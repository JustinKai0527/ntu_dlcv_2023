{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchview import draw_graph\n",
    "import torch\n",
    "from DDPM_Unet import Conditional_Denoised_Unet\n",
    "import graphviz\n",
    "\n",
    "graphviz.set_jupyter_format('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchgraph see error message",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ander\\miniconda3\\envs\\dlcvhw2\\lib\\site-packages\\torchview\\torchview.py:256\u001b[0m, in \u001b[0;36mforward_prop\u001b[1;34m(model, x, device, model_graph, mode, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m--> 256\u001b[0m     _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)(\u001b[39m*\u001b[39mx, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    257\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, Mapping):\n",
      "File \u001b[1;32mc:\\Users\\ander\\miniconda3\\envs\\dlcvhw2\\lib\\site-packages\\torchview\\recorder_tensor.py:146\u001b[0m, in \u001b[0;36mmodule_forward_wrapper.<locals>._module_forward_wrapper\u001b[1;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39m# TODO: check if output contains RecorderTensor\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39m# this seems not to be necessary so far\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m out \u001b[39m=\u001b[39m _orig_module_forward(mod, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    148\u001b[0m model_graph\u001b[39m.\u001b[39mcontext_tracker[\u001b[39m'\u001b[39m\u001b[39mcurrent_depth\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m cur_depth\n",
      "File \u001b[1;32mc:\\Users\\ander\\miniconda3\\envs\\dlcvhw2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ander\\OneDrive\\桌面\\dlcvhw2\\DDPM_Unet.py:127\u001b[0m, in \u001b[0;36mConditional_Denoised_Unet.forward\u001b[1;34m(self, x, y, t, mask)\u001b[0m\n\u001b[0;32m    125\u001b[0m latent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_latent(x2)\n\u001b[1;32m--> 127\u001b[0m y \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mone_hot(y, num_classes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_cls)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m    128\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_cls)\n",
      "File \u001b[1;32mc:\\Users\\ander\\miniconda3\\envs\\dlcvhw2\\lib\\site-packages\\torchview\\recorder_tensor.py:241\u001b[0m, in \u001b[0;36mRecorderTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[39m# use original torch_function; otherwise,\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[39m# it leads to infinite recursive call of torch_function\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m__torch_function__(func, types, args, kwargs)\n\u001b[0;32m    243\u001b[0m \u001b[39m# if no RecorderTensor is found in input or output\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[39m# dont create any node, give the result only\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ander\\miniconda3\\envs\\dlcvhw2\\lib\\site-packages\\torch\\_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1294\u001b[0m \u001b[39mwith\u001b[39;00m _C\u001b[39m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1295\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1296\u001b[0m     \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m get_default_nowrap_functions():\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one_hot is only applicable to index tensor.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ander\\OneDrive\\桌面\\dlcvhw2\\model_architecture.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ander/OneDrive/%E6%A1%8C%E9%9D%A2/dlcvhw2/model_architecture.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_graph1 \u001b[39m=\u001b[39m draw_graph(Conditional_Denoised_Unet(), input_size\u001b[39m=\u001b[39;49m[(\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m28\u001b[39;49m, \u001b[39m28\u001b[39;49m), (\u001b[39m3\u001b[39;49m,), (\u001b[39m3\u001b[39;49m,), (\u001b[39m3\u001b[39;49m,)])\n",
      "File \u001b[1;32mc:\\Users\\ander\\miniconda3\\envs\\dlcvhw2\\lib\\site-packages\\torchview\\torchview.py:220\u001b[0m, in \u001b[0;36mdraw_graph\u001b[1;34m(model, input_data, input_size, graph_name, depth, device, dtypes, mode, strict, expand_nested, graph_dir, hide_module_functions, hide_inner_tensors, roll, show_shapes, save_graph, filename, directory, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m input_recorder_tensor, kwargs_record_tensor, input_nodes \u001b[39m=\u001b[39m process_input(\n\u001b[0;32m    212\u001b[0m     input_data, input_size, kwargs, device, dtypes\n\u001b[0;32m    213\u001b[0m )\n\u001b[0;32m    215\u001b[0m model_graph \u001b[39m=\u001b[39m ComputationGraph(\n\u001b[0;32m    216\u001b[0m     visual_graph, input_nodes, show_shapes, expand_nested,\n\u001b[0;32m    217\u001b[0m     hide_inner_tensors, hide_module_functions, roll, depth\n\u001b[0;32m    218\u001b[0m )\n\u001b[1;32m--> 220\u001b[0m forward_prop(\n\u001b[0;32m    221\u001b[0m     model, input_recorder_tensor, device, model_graph,\n\u001b[0;32m    222\u001b[0m     model_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_record_tensor\n\u001b[0;32m    223\u001b[0m )\n\u001b[0;32m    225\u001b[0m model_graph\u001b[39m.\u001b[39mfill_visual_graph()\n\u001b[0;32m    227\u001b[0m \u001b[39mif\u001b[39;00m save_graph:\n",
      "File \u001b[1;32mc:\\Users\\ander\\miniconda3\\envs\\dlcvhw2\\lib\\site-packages\\torchview\\torchview.py:264\u001b[0m, in \u001b[0;36mforward_prop\u001b[1;34m(model, x, device, model_graph, mode, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown input type\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    263\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to run torchgraph see error message\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m     model\u001b[39m.\u001b[39mtrain(saved_model_mode)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchgraph see error message"
     ]
    }
   ],
   "source": [
    "model_graph1 = draw_graph(Conditional_Denoised_Unet(), input_size=[(3, 3, 28, 28), (3,), (3,), (3,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_graph1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ander\\OneDrive\\桌面\\dlcvhw2\\model_architecture.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ander/OneDrive/%E6%A1%8C%E9%9D%A2/dlcvhw2/model_architecture.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_graph1\u001b[39m.\u001b[39mvisual_graph\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_graph1' is not defined"
     ]
    }
   ],
   "source": [
    "model_graph1.visual_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visual_graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcvhw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
